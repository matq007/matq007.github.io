<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog/Weblink on Martin Proks</title><link>/tags/blog/weblink/</link><description>Recent content in Blog/Weblink on Martin Proks</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 23 Feb 2026 08:00:00 +0000</lastBuildDate><atom:link href="/tags/blog/weblink/index.xml" rel="self" type="application/rss+xml"/><item><title>Pachter et al., 2026 bioRxiv</title><link>/blog/2026/pachter-et-al.-2026-biorxiv/</link><pubDate>Mon, 23 Feb 2026 08:00:00 +0000</pubDate><guid>/blog/2026/pachter-et-al.-2026-biorxiv/</guid><description>&lt;p&gt;The work of &lt;em&gt;Pachter et al.&lt;/em&gt;, focuses on porting well established &lt;a href="https://bioconductor.org/packages/release/bioc/html/edgeR.html"&gt;edgeR&lt;/a&gt; package to Python (edgePython) using Claude Opus 4.5, 4.6 and Codex. As described in the paper, the edgeR is a non trivial package supporting various functions used for differential expression analysis in genomics research. Due to Python&amp;rsquo;s popularity in data science, having edgeR natively available in Python ecosystem, would be highly beneficial for the scientific community. Although, there exists alternative solutions of combining/converting R and Python objects interchangeably,&lt;sup id="fnref:1"&gt;&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref"&gt;1&lt;/a&gt;&lt;/sup&gt; they can be cumbersome.&lt;/p&gt;</description></item><item><title>The missing semester from MIT 2026</title><link>/blog/2026/the-missing-semester-from-mit-2026/</link><pubDate>Mon, 23 Feb 2026 08:00:00 +0000</pubDate><guid>/blog/2026/the-missing-semester-from-mit-2026/</guid><description>&lt;p&gt;The famous &lt;a href="https://missing.csail.mit.edu"&gt;IAP 2026&lt;/a&gt; course which teaches the fundamentals not covered in classic CS classes has been finally updated and released. I always like these types of courses as they are nice refresher for some fundamentals, but manage to always surprise me with some new tricks.&lt;/p&gt;</description></item><item><title>AlexsJones/llmfit</title><link>/blog/2026/llmfit/</link><pubDate>Sun, 22 Feb 2026 08:00:00 +0000</pubDate><guid>/blog/2026/llmfit/</guid><description>&lt;p&gt;&lt;a href="https://github.com/AlexsJones/llmfit"&gt;llmfit&lt;/a&gt; written by Alex Jones can help you figure out which LLM model best fits your gear setup. Versatile tools with many settings.&lt;/p&gt;
&lt;p&gt;Written in Rut, can be installed with &lt;code&gt;cargo&lt;/code&gt; or &lt;code&gt;brew&lt;/code&gt;&lt;/p&gt;
&lt;div class="codeblock"&gt;
 &lt;div class="codeblock-actions"&gt;
 &lt;button type="button"
 class="codeblock-action codeblock-action--wrap"
 data-wrap-toggle
 data-icon-button
 aria-pressed="false"
 title="Enable soft wrap"
 data-wrap-title="Enable soft wrap"
 data-nowrap-title="Disable soft wrap"&gt;
 &lt;svg viewBox="0 0 24 24" aria-hidden="true" focusable="false"&gt;
 &lt;path d="M4 6h16M4 10h12a4 4 0 0 1 0 8h-2" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round"/&gt;
 &lt;path d="M14 18l-2-2m2 2l-2 2" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"/&gt;
 &lt;/svg&gt;
 &lt;/button&gt;

 &lt;button type="button"
 class="codeblock-action codeblock-action--copy"
 data-copy-code
 data-icon-button
 title="Copy code"
 data-copied-title="COPIED"&gt;
 &lt;svg class="icon-copy" viewBox="0 0 24 24" aria-hidden="true" focusable="false"&gt;
 &lt;rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor" stroke-width="2" fill="none"&gt;&lt;/rect&gt;
 &lt;path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round"&gt;&lt;/path&gt;
 &lt;/svg&gt;
 &lt;svg class="icon-check" viewBox="0 0 24 24" aria-hidden="true" focusable="false"&gt;
 &lt;path d="M20 6L9 17l-5-5" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"&gt;&lt;/path&gt;
 &lt;/svg&gt;
 &lt;/button&gt;
 &lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;brew tap AlexsJones/llmfit
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;brew install llmfit&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and then simply running&lt;/p&gt;</description></item><item><title>Text classification with zstd</title><link>/blog/2026/text-classification-with-zstd/</link><pubDate>Sun, 15 Feb 2026 08:00:00 +0000</pubDate><guid>/blog/2026/text-classification-with-zstd/</guid><description>&lt;p&gt;&lt;a href="https://maxhalford.github.io/blog/text-classification-zstd/"&gt;Max Halford&lt;/a&gt; showcases how Zstandard compression (zstd) library from Facebook can be used for text classification. This is achieved because the zstd supports incremental compression. The trick Max shows is that one can build multiple topic classifiers and the one returning the smallest size when using test set, is the right one. The module (&lt;code&gt;compression.zstd&lt;/code&gt;) was introduced in Python 3.14. There is an interesting &lt;a href="https://news.ycombinator.com/item?id=46942864"&gt;discussion on HN&lt;/a&gt; about limitations of this approach for AI.&lt;/p&gt;</description></item><item><title>LLM Visualization</title><link>/blog/2026/llm-visualization/</link><pubDate>Sun, 08 Feb 2026 08:00:00 +0000</pubDate><guid>/blog/2026/llm-visualization/</guid><description>&lt;p&gt;&lt;a href="https://bbycroft.net"&gt;Brendan Bycroft&lt;/a&gt; created &lt;a href="https://bbycroft.net/llm"&gt;an online app&lt;/a&gt; which visually walks you through architecture and steps of LLM models (GPT-2 small, nano-gpt, GT2 (XL) or GPT-3).&lt;/p&gt;</description></item><item><title>Epsilon in AdamW matters</title><link>/blog/2026/epsilon-in-adamw-matters/</link><pubDate>Sat, 24 Jan 2026 12:00:00 +0000</pubDate><guid>/blog/2026/epsilon-in-adamw-matters/</guid><description>&lt;p&gt;When training LLM, &lt;a href="https://sifal.social"&gt;Sifal&lt;/a&gt; shows that switching from default &lt;code&gt;eps=1e-8&lt;/code&gt; to &lt;code&gt;eps=1e-10&lt;/code&gt; in AdamW optimizer can lead to better results. He showcases this on his toy example where default epsilon oscillates when searching for local minima compared to proposed one. However, this only applies when training is &lt;strong&gt;NOT&lt;/strong&gt; done with &lt;a href="https://docs.pytorch.org/docs/stable/notes/numerical_accuracy.html#reduced-precision-reduction-for-fp16-and-bf16-gemms"&gt;half-precision&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Klioui, S. (2026). The Epsilon Trap: When Adam Stops Being Adam. Sifal Klioui Blog. &lt;a href="https://sifal.social/posts/The-Epsilon-Trap-When-Adam-Stops-Being-Adam/"&gt;link&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</description></item><item><title>microsoft/BitNet</title><link>/blog/2026/bitnet/</link><pubDate>Sat, 24 Jan 2026 12:00:00 +0000</pubDate><guid>/blog/2026/bitnet/</guid><description>&lt;p&gt;A new paradigm shift from Microsoft called &lt;a href="https://github.com/microsoft/BitNet"&gt;BitNet&lt;/a&gt;, where the objective is to reduce speed and footprint of LLM models, by storing the LLM weights as 1bit. This is done during training, compared to quantization which fixes the weights post training. Authors report promising benchmarking with &lt;em&gt;BitNet b1.58 2B&lt;/em&gt; using only &lt;strong&gt;400MB&lt;/strong&gt; RAM and 29ms latency. It will be interesting to see where we will see these types of models deployed in future. Targets could be phones, IoT or privacy focused closed offline systems. For more in-depth details, I highly recommend watching &lt;a href="https://www.youtube.com/watch?v=WBm0nyDkVYM"&gt;this&lt;/a&gt; great explanation by &lt;a href="https://www.patreon.com/JuliaTurc"&gt;Julia Turc&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Osteoarthritis could be treated in future with drug inhibitor</title><link>/blog/2026/osteoarthritis-could-be-treated-in-future-with-drug-inhibitor/</link><pubDate>Sat, 24 Jan 2026 12:00:00 +0000</pubDate><guid>/blog/2026/osteoarthritis-could-be-treated-in-future-with-drug-inhibitor/</guid><description>&lt;p&gt;A new research from Stanford showed promising results tackling osteoarthritis (degenerative joint disease) by inhibition of 15-hydroxy prostaglandin dehydrogenase (15-PGDH). They categorize this gene as gerozyme, meaning it increases its activity with age. The research shows that inhibition (down-regulation of signal) helps with &lt;strong&gt;rejuvenation&lt;/strong&gt; of the cartilage. The hope is that in future, simple drug treatment could help with restoration of cartilage targeting elderly population, post-surgery patients or ACL-like injuries. This could be huge for osteoarthritis since cartilage rejuvenation is primarily done with stem cells. So far phase 1 clinical trials confirmed safety of drug administration in mice.&lt;/p&gt;</description></item></channel></rss>